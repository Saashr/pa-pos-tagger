Functionality:
- tqdm for prediction?
- Tokenization for tokenizers that do not use ## or ‚ñÅ, for example luke-large (the EN version)
- Metrics might be broken (accuracy is), because of distinction between UNK/PAD
- freeze or random seems to be broken (if frozen and random performance is still high): guess its freezing
- pick last subwords embedding for decoder only models for classification ('encoder' in str(model))
- Memory usage goes up when reaching the final prediction step
- report average instead of sum?
- Metrics do not match after saving/loading the model?! (try EWT for 5 steps, and LAS is one off in "correct" counts)
- When downloading model it is now logged as ERROR - STDERR

Clean later:
- Batches should just be a class instead of a dict
- remove scalars parameters warning
- Fix wiki.sh?
- "." can not be part of a task name because of scalars dict, should scalars be in task_decoders?
- Remove dependency on numpy (/jsonnet?)
- FutureWarning: This implementation of AdamW is deprecated.  Use the PyTorch implementation torch.optim.AdamW instead
- Add support for parameter overriding from command line: python3 train.py --dataset_config configs/ewt.json --parameter transformer_model=xlm-roberta-large,batching.sampling_smoothing=0.5
- output all tasks with predict somehow
- /home/robv/machamp/predict.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.


functionality later:
- Tune threshold of multiseq and multiclas automatically
- label balancing
- seq2seq task
- Multi-F1
- support longer input by classifying multiple cls tokens at once?
- QUAD-like tasks: https://huggingface.co/docs/transformers/model_doc/roberta#transformers.RobertaForQuestionAnswering
- support other subword strategies
- early stopping (less stable with slanted triangular LR)?

